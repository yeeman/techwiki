# 数据归一化
数据标准化（归一化）处理是数据挖掘的一项基础工作，不同评价指标往往具有不同的量纲和量纲单位，
这样的情况会影响到数据分析的结果，为了消除指标之间的量纲影响，需要进行数据标准化处理，以解决数据指标之间的可比性。
原始数据经过数据标准化处理后，各指标处于同一数量级，适合进行综合对比评价。以下是两种常用的归一化方法：

1. min-max标准化（Min-Max Normalization）

也称为离差标准化，是对原始数据的线性变换，使结果值映射到[0 - 1]之间。转换函数如下：   
`x'=(x-min)/(min+max)`    
其中max为样本数据的最大值，min为样本数据的最小值。这种方法有个缺陷就是当有新数据加入时，可能导致max和min的变化，需要重新定义。


2. Z-score标准化方法

这种方法给予原始数据的均值（mean）和标准差（standard deviation）进行数据的标准化。
经过处理的数据符合标准正态分布，即均值为0，标准差为1，转化函数为
![Z-scor](http://images.cnitblog.com/blog/407700/201307/31105201-fa88e179a3ed46e99372f1804a914c4f.gif)
其中miu为所有样本数据的均值，delta为所有样本数据的标准差。

# 正态分布
根据中心极限定理，如果一个事物受到多种因素的影响，不管每个因素本身是什么分布，它们加总后，结果的平均值就是正态分布。

如果各种因素对结果的影响不是相加，而是相乘，那么最终结果不是正态分布，而是对数正态分布（log normal distribution），即x的对数值log(x)满足正态分布。

# 雅克比矩阵 海森矩阵
在向量分析中, 雅可比矩阵是一阶偏导数以一定方式排列成的矩阵。其行列式称为雅可比行列式。

雅可比矩阵的重要性在于它体现了一个可微方程与给出点的最优线性逼近. 因此, 雅可比矩阵类似于多元函数的导数。

海森矩阵是一个以自变量为向量的实值函数的二阶偏导数组成的方块矩阵。